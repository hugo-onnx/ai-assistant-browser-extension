API_KEY=your-groq-api-key-here
MODEL=llama-3.1-8b-instant

# Sampling parameters (optional)
TEMPERATURE=1.0       # 0.0–2.0. Higher = more random, lower = more deterministic
TOP_P=1.0             # 0.0–1.0. Nucleus sampling threshold
MAX_COMPLETION_TOKENS=8192  # Max tokens in the response

# Always true — proxy only exposes the streaming endpoint
STREAM=true

ALLOWED_ORIGINS=*
